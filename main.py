import requests
import json
import csv
import os
import subprocess
import shutil
import tempfile
from datetime import datetime
from pathlib import Path
import time

class GitHubAnalyzer:
    def __init__(self, token):
        """
        Inicializa o analisador com token de acesso do GitHub
        """

        self.token = token
        self.headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
        self.base_url = "https://api.github.com/graphql"
        self.temp_dir = tempfile.mkdtemp()
        self.ck_jar_path = "ck/target/ck-0.7.1-SNAPSHOT-jar-with-dependencies.jar"
    
    def create_graphql_query(self, cursor=None):
        """
        Cria a query GraphQL para buscar os reposit√≥rios mais populares
        """

        after_clause = f', after: "{cursor}"' if cursor else ""
        
        query = f"""
        query {{
            search(query: "stars:>1000 language:java", type: REPOSITORY, first: 20{after_clause}) {{
                pageInfo {{
                    hasNextPage
                    endCursor
                }}
                nodes {{
                    ... on Repository {{
                        name
                        owner {{
                            login
                        }}
                        stargazerCount
                        createdAt
                        primaryLanguage {{
                            name
                        }}
                        releases {{
                            totalCount
                        }}
                        url
                        description
                    }}
                }}
            }}
        }}
        """
        return query
    
    def make_request(self, query):
        """
        Faz a requisi√ß√£o GraphQL para a API do GitHub
        """

        payload = {"query": query}
        
        try:
            response = requests.post(
                self.base_url,
                headers=self.headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                return response.json()
            elif response.status_code == 401:
                print("ERRO: Token inv√°lido ou expirado!")
                print("Verifique se seu token GitHub est√° correto e tem as permiss√µes necess√°rias.")
                return None
            elif response.status_code == 403:
                print("ERRO: Rate limit atingido ou permiss√µes insuficientes!")
                print("Aguarde alguns minutos ou verifique as permiss√µes do token.")
                return None
            elif response.status_code >= 500:
                print(f"ERRO: Problema tempor√°rio no servidor GitHub (C√≥digo {response.status_code})")
                print("Tente novamente em alguns minutos.")
                return None
            else:
                print(f"Erro na requisi√ß√£o: {response.status_code}")
                print(f"Resposta: {response.text}")
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"Erro de conex√£o: {e}")
            return None
    
    def calculate_age_days(self, created_at):
        """
        Calcula a idade do reposit√≥rio em dias
        """

        created_date = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
        current_date = datetime.now(created_date.tzinfo)
        return (current_date - created_date).days

    def process_repository_data(self, repo):
        """
        Processa os dados de um reposit√≥rio individual
        """

        return {
            'name': repo['name'],
            'owner': repo['owner']['login'],
            'url': repo['url'],
            'description': repo['description'] or "",
            'stars': repo['stargazerCount'],
            'age_days': self.calculate_age_days(repo['createdAt']),
            'primary_language': repo['primaryLanguage']['name'] if repo['primaryLanguage'] else "Unknown",
            'total_releases': repo['releases']['totalCount'],
            'created_at': repo['createdAt']
        }
    
    def collect_repositories_data(self, limit=100):
        """
        Coleta dados dos reposit√≥rios mais populares
        """

        repositories = []
        cursor = None
        collected = 0
        
        print(f"Iniciando coleta de dados para {limit} reposit√≥rios...")
        
        while collected < limit:
            query = self.create_graphql_query(cursor)
            response_data = self.make_request(query)
            
            if not response_data or 'data' not in response_data:
                print("Erro ao obter dados da API")
                break
            
            search_results = response_data['data']['search']
            repos = search_results['nodes']
            
            for repo in repos:
                if collected >= limit:
                    break
                    
                try:
                    processed_repo = self.process_repository_data(repo)
                    repositories.append(processed_repo)
                    collected += 1
                    
                    if collected % 20 == 0:
                        print(f"Coletados {collected}/{limit} reposit√≥rios... ({(collected/limit)*100:.1f}%)")
                        
                except Exception as e:
                    print(f"Erro ao processar reposit√≥rio {repo.get('name', 'Unknown')}: {e}")
                    continue
            
            if not search_results['pageInfo']['hasNextPage'] or collected >= limit:
                break
                
            cursor = search_results['pageInfo']['endCursor']
            
            time.sleep(3)
        
        print(f"Coleta finalizada. Total coletado: {len(repositories)} reposit√≥rios")
        return repositories
    
    def clone_repository(self, repo_url, repo_name):
        """
        Clona um reposit√≥rio para an√°lise
        """
        clone_path = os.path.join(self.temp_dir, repo_name)
        
        try:
            if os.path.exists(clone_path):
                shutil.rmtree(clone_path)
            
            print(f"Clonando reposit√≥rio: {repo_url}")
            subprocess.run([
                "git", "clone", "--depth", "1", repo_url, clone_path
            ], check=True, capture_output=True, text=True)
            
            return clone_path
            
        except subprocess.CalledProcessError as e:
            print(f"Erro ao clonar reposit√≥rio {repo_url}: {e}")
            return None
    
    def run_ck_analysis(self, repo_path):
        """
        Executa an√°lise CK no reposit√≥rio clonado
        """
        try:
            if not os.path.exists(self.ck_jar_path):
                print(f"Arquivo CK n√£o encontrado: {self.ck_jar_path}")
                return None
            
            # Garante que a pasta temp existe
            temp_path = "temp"
            os.makedirs(temp_path, exist_ok=True)
            
            print(f"Executando an√°lise CK em: {repo_path}")
            
            # Comando para executar CK
            cmd = [
                "java", "-jar", self.ck_jar_path,
                repo_path,
                "true",  # usar diret√≥rios
                "0",     # m√°ximo arquivos
                "true",  # usar jarfiles
                "temp/"
            ]
            
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                cwd=os.getcwd(),
                timeout=300  # 5 minutos timeout
            )
            
            if result.returncode == 0:
                print("An√°lise CK conclu√≠da com sucesso")
                return self.parse_ck_results_from_temp()
            else:
                print(f"Erro na an√°lise CK: {result.stderr}")
                return None
                
        except subprocess.TimeoutExpired:
            print("Timeout na an√°lise CK")
            return None
        except Exception as e:
            print(f"Erro ao executar CK: {e}")
            return None
    
    def parse_ck_results_from_temp(self):
        """
        Parse dos resultados do CK da pasta temp/
        """
        temp_path = "temp"
        
        try:
            # Arquivos CK gerados na pasta temp/
            class_csv = os.path.join(temp_path, "class.csv")
            
            metrics = {
                'total_classes': 0,
                'total_methods': 0,
                'total_fields': 0,
                'total_variables': 0,
                'avg_wmc': 0,
                'cbo': 0,
                'lcom': 0,
                'dit': 0,
                'avg_noc': 0,
                'avg_rfc': 0,
                'loc': 0,
                'avg_cc': 0
            }
            
            print(f"Extraindo m√©tricas dos arquivos CSV...")
            
            # Parse class metrics
            if os.path.exists(class_csv):
                print(f"Processando {class_csv}")
                with open(class_csv, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    classes = list(reader)
                    metrics['total_classes'] = len(classes)
                    
                    if classes:
                        metrics['cbo'] = sum(float(c.get('cbo', 0)) for c in classes)
                        metrics['lcom'] = sum(float(c.get('lcom', 0)) for c in classes)
                        metrics['dit'] = sum(float(c.get('dit', 0)) for c in classes)
                        metrics['loc'] = sum(float(c.get('loc', 0)) for c in classes)
            
            # Limpa arquivos CSV da pasta temp
            self.cleanup_temp_csv_files()
            
            print(f"‚úì M√©tricas extra√≠das: {metrics['total_classes']} classes")
            return metrics
            
        except Exception as e:
            print(f"Erro ao parsear resultados CK: {e}")
            # Tenta limpar arquivos mesmo em caso de erro
            self.cleanup_temp_csv_files()
            return None
    
    def cleanup_temp_csv_files(self):
        """
        Remove arquivos CSV da pasta temp ap√≥s extrair m√©tricas
        """
        temp_path = "temp"
        csv_files = ["class.csv", "method.csv", "field.csv", "variable.csv"]
        
        for csv_file in csv_files:
            file_path = os.path.join(temp_path, csv_file)
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
                    print(f"üóëÔ∏è Removido: {csv_file}")
            except Exception as e:
                print(f"Erro ao remover {csv_file}: {e}")
    
    def process_single_repository(self, repo):
        """
        Processa um √∫nico reposit√≥rio: clona, executa CK e retorna m√©tricas
        """
        repo_name = f"{repo['owner']}_{repo['name']}"
        clone_url = f"https://github.com/{repo['owner']}/{repo['name']}.git"
        
        print(f"\nProcessando reposit√≥rio: {repo['owner']}/{repo['name']}")
        
        # Clona reposit√≥rio
        repo_path = self.clone_repository(clone_url, repo_name)
        if not repo_path:
            return None
        
        try:
            # Executa an√°lise CK
            ck_metrics = self.run_ck_analysis(repo_path)
            
            if ck_metrics:
                # Combina dados do reposit√≥rio com m√©tricas CK
                result = {
                    'name': repo['name'],
                    'owner': repo['owner'],
                    'url': repo['url'],
                    'description': repo['description'],
                    'stars': repo['stars'],
                    'age_days': repo['age_days'],
                    'primary_language': repo['primary_language'],
                    'total_releases': repo['total_releases'],
                    'created_at': repo['created_at'],
                    **ck_metrics
                }
                
                # Limpa reposit√≥rio imediatamente ap√≥s an√°lise bem-sucedida
                print(f"An√°lise CK conclu√≠da. Removendo reposit√≥rio clonado...")
                self.cleanup_repo(repo_path)
                
                return result
            else:
                print(f"Falha na an√°lise CK para {repo_name}")
                # Limpa reposit√≥rio mesmo em caso de falha
                print(f"Removendo reposit√≥rio clonado...")
                self.cleanup_repo(repo_path)
                return None
                
        except Exception as e:
            print(f"Erro durante processamento: {e}")
            # Limpa reposit√≥rio em caso de erro
            print(f"Removendo reposit√≥rio clonado...")
            self.cleanup_repo(repo_path)
            return None
    
    def append_to_csv(self, repo_data, filename="repositories_ck_analysis.csv"):
        """
        Adiciona uma linha ao CSV (para processamento incremental)
        """
        fieldnames = [
            'name', 'owner', 'url', 'description', 'stars',
            'age_days', 'primary_language', 'total_releases', 'created_at',
            'total_classes', 'total_methods', 'total_fields', 'total_variables',
            'avg_wmc', 'cbo', 'lcom', 'dit', 'avg_noc', 'avg_rfc',
            'loc', 'avg_cc'
        ]
        
        file_exists = os.path.exists(filename)
        
        with open(filename, 'a', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            if not file_exists:
                writer.writeheader()
            writer.writerow(repo_data)
        
        print(f"Dados de {repo_data['owner']}/{repo_data['name']} adicionados ao CSV")
    
    def analyze_repositories_with_ck(self, limit=10):
        """
        Coleta TODOS os reposit√≥rios primeiro, depois processa um por um com CK
        """
        csv_filename = "repositories_ck_analysis.csv"
        
        # PRIMEIRO: Remove CSV antigo se existir
        if os.path.exists(csv_filename):
            try:
                os.remove(csv_filename)
                print(f"üóëÔ∏è CSV antigo removido: {csv_filename}")
            except Exception as e:
                print(f"Erro ao remover CSV antigo: {e}")
        
        print(f"Iniciando coleta de reposit√≥rios...")
        
        # SEGUNDO: Coleta TODOS os dados dos reposit√≥rios
        repositories = self.collect_repositories_data(limit)
        
        if not repositories:
            print("Nenhum reposit√≥rio encontrado")
            return []
        
        print(f"\n{'='*60}")
        print(f"COLETA FINALIZADA!")
        print(f"Total de reposit√≥rios coletados: {len(repositories)}")
        print(f"Dados completos salvos na vari√°vel 'repositories'")
        print(f"{'='*60}")
        
        # Exibe resumo dos reposit√≥rios coletados
        print("\nReposit√≥rios que ser√£o analisados:")
        for i, repo in enumerate(repositories, 1):
            print(f"{i:3d}. {repo['owner']}/{repo['name']} ({repo['stars']:,} ‚≠ê)")
        
        print(f"\n{'='*60}")
        print("INICIANDO AN√ÅLISE CK...")
        print(f"{'='*60}")
        
        processed_repos = []
        
        # SEGUNDO: Processa cada reposit√≥rio com CK (um por vez)
        for i, repo in enumerate(repositories, 1):
            print(f"\n{'='*60}")
            print(f"ANALISANDO {i}/{len(repositories)}: {repo['owner']}/{repo['name']}")
            print(f"URL: {repo['url']}")
            print(f"Stars: {repo['stars']:,} | Linguagem: {repo['primary_language']}")
            print(f"{'='*60}")
            
            # Processa reposit√≥rio individual
            result = self.process_single_repository(repo)
            
            if result:
                # Adiciona ao CSV imediatamente
                self.append_to_csv(result, csv_filename)
                processed_repos.append(result)
                print(f"‚úÖ Reposit√≥rio processado com sucesso")
            else:
                print(f"‚ùå Falha no processamento do reposit√≥rio")
                
            
            # Pausa entre reposit√≥rios para evitar sobrecarga
            if i < len(repositories):
                print("Aguardando 3 segundos...")
                time.sleep(3)
        
        print(f"\n{'='*60}")
        print(f"AN√ÅLISE CK FINALIZADA!")
        print(f"Reposit√≥rios processados com sucesso: {len(processed_repos)}/{len(repositories)}")
        print(f"Resultados salvos em: {csv_filename}")
        print(f"{'='*60}")
        
        return processed_repos
    
    def cleanup_repo(self, repo_path):
        """
        Remove um reposit√≥rio espec√≠fico imediatamente
        """
        try:
            if repo_path and os.path.exists(repo_path):
                shutil.rmtree(repo_path)
                print(f"‚úì Reposit√≥rio removido: {os.path.basename(repo_path)}")
                return True
        except Exception as e:
            print(f"‚úó Erro ao remover reposit√≥rio {repo_path}: {e}")
            return False
    
    def cleanup(self):
        """
        Limpa diret√≥rio tempor√°rio completo
        """
        try:
            if os.path.exists(self.temp_dir):
                shutil.rmtree(self.temp_dir)
                print(f"Diret√≥rio tempor√°rio removido: {self.temp_dir}")
        except Exception as e:
            print(f"Erro ao limpar diret√≥rio tempor√°rio: {e}")
    
    def print_summary(self, repositories):
        """
        Imprime um resumo dos dados coletados
        """

        if not repositories:
            return
        
        print("\n" + "="*50)
        print("RESUMO DOS DADOS COLETADOS")
        print("="*50)
        
        print(f"Total de reposit√≥rios: {len(repositories)}")
        
        ages = [repo['age_days'] for repo in repositories]
        stars = [repo['stars'] for repo in repositories]
        releases = [repo['total_releases'] for repo in repositories]
        
        print(f"\nIdade dos reposit√≥rios:")
        print(f"  Mediana: {sorted(ages)[len(ages)//2]} dias")
        print(f"  M√©dia: {sum(ages)/len(repositories):.1f} dias")
        print(f"  M√≠nima: {min(ages)} dias")
        print(f"  M√°xima: {max(ages)} dias")
        
        print(f"\nEstrelas:")
        print(f"  Mediana: {sorted(stars)[len(stars)//2]:,}")
        print(f"  M√©dia: {sum(stars)/len(repositories):.1f} dias")
        print(f"  M√≠nima: {min(stars):,}")
        print(f"  M√°xima: {max(stars):,}")

        print(f"\nReleases:")
        print(f"  Mediana: {sorted(releases)[len(releases)//2]:,}")
        print(f"  M√©dia: {sum(releases)/len(repositories):.1f}")
        print(f"  M√°ximo: {max(releases):,}")

def load_env_file():
    """
    Carrega vari√°veis de ambiente de um arquivo .env (opcional)
    """

    try:
        if os.path.exists('.env'):
            with open('.env', 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        os.environ[key.strip()] = value.strip()
    except Exception as e:
        pass


def main():
    """
    Fun√ß√£o principal do programa
    """

    load_env_file()
    
    token = os.getenv('GITHUB_TOKEN')
    
    if not token:
        print("ERRO: Token do GitHub n√£o encontrado!")
        return

    analyzer = GitHubAnalyzer(token)
    
    try:
        # Processa reposit√≥rios com an√°lise CK (um por vez)
        processed_repos = analyzer.analyze_repositories_with_ck(limit=2)
        
        if processed_repos:
            print(f"\n{'='*60}")
            print("RESUMO DA AN√ÅLISE CK")
            print(f"{'='*60}")
            print(f"Reposit√≥rios analisados: {len(processed_repos)}")
            
            if processed_repos:
                # Estat√≠sticas das m√©tricas CK
                stars = [r.get('stars', 0) for r in processed_repos if r.get('stars')]
                loc = [r.get('loc', 0) for r in processed_repos if r.get('loc')]
                releases = [r.get('releases', 0) for r in processed_repos if r.get('releases')]
                age = [r.get('age_days', 0) for r in processed_repos if r.get('age_days')]

                cbo = [r.get('cbo', 0) for r in processed_repos if r.get('cbo')]
                dit = [r.get('dit', 0) for r in processed_repos if r.get('dit')]
                lcom = [r.get('lcom', 0) for r in processed_repos if r.get('lcom')]

                
                
                print('M√©tricas de processo:  \n')

                if stars:
                    print(f"M√©dia de estrelas por reposit√≥rio: {sum(stars)/len(processed_repos):.1f} ‚≠ê")
                if loc:
                    print(f"M√©dia de linhas de c√≥digo: {sum(loc)/len(processed_repos):.2f}")
                if releases:
                    print(f"M√©dia de atividade: {sum(releases)/len(processed_repos):.2f}")
                if age:
                    print(f"M√©dia de maturidade: {sum(age)/len(processed_repos):.2f}")

                print('\n ---------------------------------------- \n')


                print('M√©tricas de qualidade:  \n')

                if cbo:
                    print(f"CBO M√©dio: {sum(cbo)/len(processed_repos):.2f}")
                if dit:
                    print(f"DIT M√©dio: {sum(dit)/len(processed_repos):.2f}")

                if lcom:
                    print(f"LCOM M√©dio: {sum(lcom)/len(processed_repos):.2f}")

        else:
            print("Nenhum reposit√≥rio foi processado com sucesso.")
    
    except KeyboardInterrupt:
        print("\n\nInterrompido pelo usu√°rio.")
    except Exception as e:
        print(f"\nErro durante a execu√ß√£o: {e}")
    finally:
        # Limpa diret√≥rio tempor√°rio
        analyzer.cleanup()


if __name__ == "__main__":
    main()
